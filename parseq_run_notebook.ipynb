{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parseq import run_parseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Run\n",
    "- Ceates a folder with the run name (run directory) in the output directory.\n",
    "- Copies raw fastq files to a folder named raw_data in the run directory.\n",
    "- Initializes a json file that will be updated throughout the analysis process to capture all important run information.\n",
    "- Provides a histograms with stats on the number of sequences, and the average, min, max, and std of sequence length.\n",
    "- Saves the histograms to /run_directory/fastq_length_histograms/raw_fastq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Run Parameters\n",
    "\n",
    "# A folder with the name of the run will be created in the output directory (path://output_directory_path/run_name)\n",
    "\n",
    "run_name='run4_2023_10_30'\n",
    "\n",
    "output_directory_path= '/home/ubuntu/notebooks/parseq_test_runs'\n",
    "\n",
    "# fastq files for each plate.\n",
    "# fastq files will be copied to /run_directory/raw_data and renamed to the plate name\n",
    "plate_naming_scheme ={ \n",
    "    #platename : path to fastq file\n",
    "    'plate05' : '/home/ubuntu/notebooks/parSEQ/raw_data/barcode05.fastq',\n",
    "    'plate06' : '/home/ubuntu/notebooks/parSEQ/raw_data/barcode06.fastq',\n",
    "    'plate07' : '/home/ubuntu/notebooks/parSEQ/raw_data/barcode07.fastq',\n",
    "       \n",
    "}\n",
    "\n",
    "# If you wish to run multiprocessing on the plates, set the number of cores here. If you wish to run on a single core, set to 1.\n",
    "# Multiprocessing will run for the most intensive part of the analysis, which are the plate demultiplexing and the well sequence alignment\n",
    "multiprocessing_cores = 4\n",
    "\n",
    "\n",
    "\n",
    "run_json_file_path = run_parseq.set_up_run(run_name,output_directory_path,plate_naming_scheme,multiprocessing_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Filtering and QC\n",
    "- Filters raw reads in fastq files for length and phred quality score.\n",
    "- Outputs a filtered fastq file along with .html and .json quality description files per plate to  /run_directory/fastp_output/plate.\n",
    "- Outputs length histogram along with length stats to /run_directory/fastq_length_histograms/post_fastp for each plate.\n",
    "- Updates json file with relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fastp', '-A', '-i', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/raw_data/plate05.fastq', '--length_required', '300', '--length_limit', '420', '-o', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate05/plate05.fastq', '-j', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate05/plate05.json', '-h', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate05/plate05.html', '-q', '10']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 301094\n",
      "total bases: 107466293\n",
      "Q20 bases: 90830756(84.5202%)\n",
      "Q30 bases: 75097227(69.8798%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 294221\n",
      "total bases: 106290937\n",
      "Q20 bases: 89864949(84.5462%)\n",
      "Q30 bases: 74304752(69.9069%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 294221\n",
      "reads failed due to low quality: 148\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 6605\n",
      "reads failed due to too long: 120\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 7.43972%\n",
      "\n",
      "JSON report: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate05/plate05.json\n",
      "HTML report: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate05/plate05.html\n",
      "\n",
      "fastp -A -i /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/raw_data/plate05.fastq --length_required 300 --length_limit 420 -o /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate05/plate05.fastq -j /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate05/plate05.json -h /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate05/plate05.html -q 10 \n",
      "fastp v0.20.1, time used: 2 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastp completed for plate05\n",
      "['fastp', '-A', '-i', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/raw_data/plate06.fastq', '--length_required', '300', '--length_limit', '420', '-o', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate06/plate06.fastq', '-j', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate06/plate06.json', '-h', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate06/plate06.html', '-q', '10']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 383941\n",
      "total bases: 136229065\n",
      "Q20 bases: 111484372(81.836%)\n",
      "Q30 bases: 82173433(60.32%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 373751\n",
      "total bases: 134628193\n",
      "Q20 bases: 110265043(81.9034%)\n",
      "Q30 bases: 81290379(60.3814%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 373751\n",
      "reads failed due to low quality: 395\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 9613\n",
      "reads failed due to too long: 182\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 6.68424%\n",
      "\n",
      "JSON report: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate06/plate06.json\n",
      "HTML report: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate06/plate06.html\n",
      "\n",
      "fastp -A -i /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/raw_data/plate06.fastq --length_required 300 --length_limit 420 -o /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate06/plate06.fastq -j /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate06/plate06.json -h /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate06/plate06.html -q 10 \n",
      "fastp v0.20.1, time used: 3 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastp completed for plate06\n",
      "['fastp', '-A', '-i', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/raw_data/plate07.fastq', '--length_required', '300', '--length_limit', '420', '-o', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate07/plate07.fastq', '-j', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate07/plate07.json', '-h', '/home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate07/plate07.html', '-q', '10']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read1 before filtering:\n",
      "total reads: 318745\n",
      "total bases: 113471454\n",
      "Q20 bases: 93652792(82.5342%)\n",
      "Q30 bases: 65523407(57.7444%)\n",
      "\n",
      "Read1 after filtering:\n",
      "total reads: 311197\n",
      "total bases: 112183695\n",
      "Q20 bases: 92631824(82.5716%)\n",
      "Q30 bases: 64796725(57.7595%)\n",
      "\n",
      "Filtering result:\n",
      "reads passed filter: 311197\n",
      "reads failed due to low quality: 187\n",
      "reads failed due to too many N: 0\n",
      "reads failed due to too short: 7242\n",
      "reads failed due to too long: 119\n",
      "\n",
      "Duplication rate (may be overestimated since this is SE data): 7.62965%\n",
      "\n",
      "JSON report: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate07/plate07.json\n",
      "HTML report: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate07/plate07.html\n",
      "\n",
      "fastp -A -i /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/raw_data/plate07.fastq --length_required 300 --length_limit 420 -o /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate07/plate07.fastq -j /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate07/plate07.json -h /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastp_output/plate07/plate07.html -q 10 \n",
      "fastp v0.20.1, time used: 2 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastp completed for plate07\n",
      "Sequence length histogram for plate05 saved to /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastq_length_histograms/post_fastp\n",
      "Sequence length histogram for plate06 saved to /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastq_length_histograms/post_fastp\n",
      "Sequence length histogram for plate07 saved to /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/fastq_length_histograms/post_fastp\n",
      "#########\n",
      "post fastp stats and length histogram completed.\n",
      "Check json file for updated stats on plates and histogram paths.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### length filtering ###\n",
    "\n",
    "# Length filtering is automatically taken as mean of the length distribution of th raw data +/- 2*standard deviation \n",
    "# If you wish to change this behavior, then please change the values in the following dictionary for the respective plate\n",
    "#Use plate names, not original barocde names\n",
    "\n",
    "#\n",
    "length_filtering_dict={\n",
    "    \n",
    "    'plate05' :  {'min':  300, 'max':  420 },\n",
    "    'plate06' :  {'min':  300, 'max':  420 },\n",
    "    'plate07' :  {'min':  300, 'max':  420 },\n",
    "    \n",
    "}\n",
    "\n",
    "# minimum quality score: qualified_quality_phred from fastp\n",
    "# the quality value that a base is qualified. Default 10 means phred quality >=Q10 is qualified.\n",
    "ngs_read_quality_filtering_dict={\n",
    "    # Default is 10\n",
    "    'plate05' :  {'min_quality_score' : 10 },\n",
    "    'plate06' :  {'min_quality_score' : 10 },\n",
    "    'plate07' :  {'min_quality_score' : 10 },\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "run_parseq.fastp_process(run_json_file_path,length_filtering_dict, ngs_read_quality_filtering_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Demultiplexing\n",
    "- Uses freebarcodes software to assign a barcode to each of the reads in each of the post_fastp fastq files.\n",
    "    - Freebarcodes decoding uses barcoding mapping csv\n",
    "    - Freebarcodes decoding does barcode search with error provided\n",
    "    - Outputs text file for each plate with barcode assigned to each read in /run_directory/freebarcodes_output\n",
    "- Separates reads from freebarcodes decoded file into respective well-level fasta files for each plate in /run_directory/demultiplexed/plate\n",
    "    - Uses constant regions to get the fwd read of any reverse read, such that the fasta files contain fwd reads only.\n",
    "    - Separation of freebarcodes decoded files into wells runs in parallel for the plates based on the multiprocessing_cores parameter provided.\n",
    "- Provides plate level csv files for demultiplexed reads and number of reads per well.\n",
    "- Updates json file with relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freebarcodes file created at /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/freebarcodes_output/freebarcodes9-1.txt\n",
      "Freebarcodes decode completed for file plate05\n",
      "Output folder: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/freebarcodes_output\n",
      "Freebarcodes decode completed for file plate06\n",
      "Output folder: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/freebarcodes_output\n",
      "Freebarcodes decode completed for file plate07\n",
      "Output folder: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/freebarcodes_output\n",
      "Separating freebarcodes decoded file into wells for plate05\n",
      "Separating freebarcodes decoded file into wells for plate07\n",
      "Separating freebarcodes decoded file into wells for plate06\n",
      "Freebarcodes decoded file separated into wells for plate05\n",
      "Output fasta folder: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/demultiplexed/plate05\n",
      " Output csv files: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/demultiplexed\n",
      "Freebarcodes decoded file separated into wells for plate07\n",
      "Output fasta folder: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/demultiplexed/plate07\n",
      " Output csv files: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/demultiplexed\n",
      "Freebarcodes decoded file separated into wells for plate06\n",
      "Output fasta folder: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/demultiplexed/plate06\n",
      " Output csv files: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/demultiplexed\n"
     ]
    }
   ],
   "source": [
    "### Demultiplexing ###\n",
    "\n",
    "#Demultiplexing decodes plates into wells using a barcode map. The barcode map is a csv file that maps the DNA barcode used in the parSEQ pipeline to the well name of a 384 well plate.\n",
    "\n",
    "\n",
    "barcode_csv_path = '/home/ubuntu/notebooks/parSEQ_repo/barcode_map.csv'\n",
    "barcode_search_error = 1\n",
    "\n",
    "\n",
    "### Outputing forward reads only ###\n",
    "# In order to output forward-read only demultiplexed well-level fasta files, we have to compare against a constant sequence that is present in the fwd reads. Note that for any reverse read, the forward read will be outputted in the fasta file.\n",
    "# Best practice: \n",
    "# 1. Use a constant region that is 30+ bases long\n",
    "# 2. Choose the sequence such that it is not at one of the extremities of the reads\n",
    "# 3. Take the fwd read of the constant sequence and add it to the dictionary below\n",
    "\n",
    "######################\n",
    "## It is mandatory to add the fwd read of a constant sequence to the fwd_read_constant_sequence_dict below fore each plate to continue analysis##\n",
    "######################\n",
    "\n",
    "fwd_read_constant_sequence_dict = {\n",
    "    \n",
    "    'plate05' : 'GATCGGAAGAGCACACGTCTGAACTCCAGTCAC',\n",
    "    'plate06' : 'GATCGGAAGAGCACACGTCTGAACTCCAGTCAC',\n",
    "    'plate07' : 'GATCGGAAGAGCACACGTCTGAACTCCAGTCAC',\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "run_parseq.demultiplex_plates(run_json_file_path,barcode_csv_path,barcode_search_error,fwd_read_constant_sequence_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alginment & Consensus\n",
    "- Aligns every demultiplexed fasta file in  /run_directory/demultiplexed/plate and outputs aligned fasta file to /run_directory/aligned/plate.\n",
    "    - Alignment algorithm options: mafft, muscle.\n",
    "    - Alignment runs in parallel for the plates based on the multiprocessing_cores parameter provided.\n",
    "- Calculates consensus sequence for every well of every plate with the provided consensus_threshold and ambiguous base.\n",
    "    - Provides plate level csv files for raw consensus and stats /run_directory/consensus/raw_consensus.\n",
    "    - Consensus runs in parallel for the plates based on the multiprocessing_cores parameter provided.\n",
    "- Provides a run level csv file for raw consensus and stats under /run_directory.\n",
    "\n",
    "Note that consensus sequences output at this step contain the well-level barcodes. They can be trimmed using the trimming and reconstruction oprion below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning plate05 with mafft\n",
      "Alignment completed for file plate05\n",
      "Output folder: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/aligned/plate05\n",
      "Aligning plate06 with mafft\n",
      "Alignment completed for file plate06\n",
      "Output folder: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/aligned/plate06\n",
      "Aligning plate07 with mafft\n",
      "Alignment completed for file plate07\n",
      "Output folder: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/aligned/plate07\n",
      "Creating raw consensus csv files for each plate\n",
      "Raw consensus csv file created for plate05\n",
      "Output file: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/consensus/raw_consensus/plate05_raw_consesus.csv\n",
      "Raw consensus csv file created for plate07\n",
      "Output file: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/consensus/raw_consensus/plate07_raw_consesus.csv\n",
      "Raw consensus csv file created for plate06\n",
      "Output file: /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/consensus/raw_consensus/plate06_raw_consesus.csv\n"
     ]
    }
   ],
   "source": [
    "### Aligning well reads and getting consensus###\n",
    "\n",
    "# Alignment algorithms: 'mafft' or 'muscle'\n",
    "# mafft is faster than muscle, but muscle is alightly more accurate\n",
    "# Default is mafft\n",
    "# mafft v7.49 is run in the --auto mode\n",
    "# muscle v3.8.425 is run in the default mode with optimal gap opening and extension penalties for pooled amplicon sequencing data\n",
    "\n",
    "alignment_algorithm = 'mafft'\n",
    "\n",
    "\n",
    "# Consusensus threshold: The minimum fraction of reads that must have the same base at a given position in order for that base to be called in the consensus sequence\n",
    "# Default is 0.6\n",
    "consensus_threshold = 0.6\n",
    "ambiguous_base = 'N' # The base that will be called if the consensus threshold is not met. Default is 'N'\n",
    "\n",
    "\n",
    "run_parseq.align_wells_and_get_consensus (run_json_file_path, alignment_algorithm, consensus_threshold,ambiguous_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming & Reconstruction\n",
    "\n",
    "Trimming and reconstruction is optional.\n",
    "- Processes consensus csv files to trim 5' and 3' end based on the trim parameters provided. Trimming is optional\n",
    "- Processes consensus csv files to add 5' and 3' end sequences based on the reconstruction parameters provided. Reconstruction is optional.\n",
    "- Provides plate level trimmed & reconstructed consensus and stats under /run_directory/consensus/trimmed_reconstructed_consensus.\n",
    "- Provides run level csv file for trimmed & reconstructed consensus and stats under /run_directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Trimming, Reconstruction of Consensus Sequences #####\n",
    "\n",
    "### Trimming parameters ###\n",
    "# If you wish to trim the reads, then add the trim parameters for every plate below\n",
    "# Trimming will occur to the left of the 5' end trim and the right of the 3' end trim (reading in the 5' -> 3' direction of fwd read)\n",
    "# If you wish to trim only one end, then leave the other end empty\n",
    "# Trimming would work best if the sequences upon which the trimming is performed are relatively long (25 bases plus).\n",
    "# Trimming is optional. If you do not wish to trim, then leave the trim_dictionary empty\n",
    "\n",
    "trim_dictionary = {\n",
    "    \n",
    "    #both of these sequences should be given in the 5' to 3' direction of the forward read\n",
    "    \n",
    "   'plate05' : {'five_prime':'CTCGGAGATGTACTAAGAGAGACCCGTT', 'three_prime':'TGAAAGGTCTCTCTTAGTAGACATCCTCGC'},\n",
    "   'plate06' : {'five_prime':'CTCGGAGATGTACTAAGAGAGACCCGTT', 'three_prime':'TGAAAGGTCTCTCTTAGTAGACATCCTCGC'},\n",
    "   'plate07' : {'five_prime':'CTCGGAGATGTACTAAGAGAGACCCGTT', 'three_prime':'TGAAAGGTCTCTCTTAGTAGACATCCTCGC'},\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "### Sequence Reconstruction Parameters###\n",
    "# If you wish to add 5' and 3' ends to your sequences add these 5' and 3' sequences below\n",
    "# You can add both 5' and 3' ends or just one of them\n",
    "# Reconstruction will run after trimming for the plates with the trimming parameters. \n",
    "# For plates without trimming parameters, reconstruction will run independently\n",
    "# If you do not wish to reconstruct, then leave the reconstruct_dictionary empty\n",
    "\n",
    "reconstruct_dictionary = {\n",
    "    \n",
    "'plate05' : {'five_prime': 'ACAAAAAAAAAAAAA', 'three_prime': ''  }, \n",
    "'plate06' : {'five_prime': 'ACAAAAAAAAAAAAA',  'three_prime': 'TTTTTTTT' },\n",
    "             \n",
    "    \n",
    "}\n",
    "\n",
    "run_parseq.trim_and_reconstruct(run_json_file_path,trim_dictionary,reconstruct_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "\n",
    "- Creates visualizations based on the consensus sequences.\n",
    "- Visualizations are based can based on raw consensus results or trimmed & reconstructed consensus results.\n",
    "- Creates both plate-level and run-level visualizations\n",
    "- Visualizations are intended to give a holistic view of the parSEQ run performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run level visualizations for raw consensus sequences created.\n",
      "Output directory:  /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/visualizations/raw_consensus_visualizations\n",
      "Plate level visualizations for raw consensus sequences created.\n",
      "Output directory:  /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/visualizations/raw_consensus_visualizations\n",
      "Run level visualizations for trimmed reconstructed consensus sequences created.\n",
      "Output directory:  /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/visualizations/trimmed_recon_consensus_visualizations\n",
      "Plate level visualizations for trimmed reconstructed consensus sequences created.\n",
      "Output directory:  /home/ubuntu/notebooks/parseq_test_runs/run4_2023_10_30/visualizations/trimmed_recon_consensus_visualizations\n"
     ]
    }
   ],
   "source": [
    "#### Result Visualization #####\n",
    "\n",
    "## For each plate, the following results will be generated:\n",
    "# Heat map of the number of reads in every well. Empty wells will appear as empty squares\n",
    "# Heat map of the number of ambiguous reads in every well. Empty wells will appear as empty squares \n",
    "# Heat map of the average read length in every well. Empty wells will appear as empty squares \n",
    "\n",
    "# Histogram of the number of reads per well for each plate\n",
    "# Histogram of the number of ambiguous reads per well for each plate \n",
    "# Histogram of the read length for each plate \n",
    "\n",
    "## On the run level, the following results will be generated:\n",
    "# bar chart of the average number of reads per plate\n",
    "# bar chart of the average read length per plate\n",
    "# bar chart of the average number of ambiguous reads per plate\n",
    "# heatmap of the average number of reads per well per plate\n",
    "# heatmap of the average number of ambiguous reads per well per plate\n",
    "# heatmap of the average read length per well per plate\n",
    "\n",
    "# You can run the visualization on:\n",
    "# 1. The raw consensus sequences by setting raw_consensus_visualizations = True\n",
    "# 2. The trimmed and reconstructed sequences by setting trimmed_reconstructed_visualizations = True\n",
    "# If you wish to run both, then set both to True\n",
    "\n",
    "# Note:\n",
    "# 1. raw consensus sequence visualizations will only be generated if the consensus sequences have been generated\n",
    "# 2. trimmed and reconstructed visualizations will only be generated if the trimmed and reconstructed sequences have been generated\n",
    "\n",
    "raw_consensus_visualizations = True\n",
    "trimmed_reconstructed_visualizations = True\n",
    "\n",
    "run_parseq.create_visualizations(run_json_file_path,raw_consensus_visualizations,trimmed_reconstructed_visualizations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
